{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepGL - Deep Feature Learning for graphs\n",
    "\n",
    "We've implemented the [DeepGL](https://arxiv.org/abs/1704.08829) algorithm as a Neo4j procedure and this notebook shows our experiments with it against a SNAP email dataset.\n",
    "\n",
    "First up let's import some things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\"bolt://localhost\", auth=(\"neo4j\", \"neo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from neo4j.v1 import GraphDatabase\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# load data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels_added': 1005, 'relationships_created': 25571, 'nodes_created': 1005, 'properties_set': 1005}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties_set': 1005}\n"
     ]
    }
   ],
   "source": [
    "edge_list_file = \"https://github.com/meltzerpete/Embedding-Vis/raw/master/emails/emails.edgelist\"\n",
    "labels_file = \"https://github.com/meltzerpete/Embedding-Vis/raw/master/emails/emails.labels\"\n",
    "attributes_file = None  # attributes file should have nodeIds in column 0, followed by one column per attribute\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Node) ASSERT n.id IS UNIQUE\")\n",
    "    \n",
    "    result = session.run(\"\"\"\\\n",
    "        LOAD CSV FROM $edgelistFile AS row\n",
    "        FIELDTERMINATOR \" \"\n",
    "        MERGE (e1:Node {id: row[0]})\n",
    "        MERGE (e2:Node {id: row[1]})\n",
    "        MERGE (e1)-[:LINK]->(e2)\n",
    "        \"\"\", {\"edgelistFile\": edge_list_file})\n",
    "    print(result.summary().counters)\n",
    "\n",
    "    result = session.run(\"\"\"\\\n",
    "        LOAD CSV FROM $labelsFile AS row\n",
    "        FIELDTERMINATOR \" \"\n",
    "        MATCH (e:Node {id: row[0]})\n",
    "        SET  e.label = toInteger(row[1])-1\n",
    "        \"\"\", {\"labelsFile\": labels_file})\n",
    "    print(result.summary().counters)\n",
    "\n",
    "    if attributes_file is not None:\n",
    "        result = session.run(\"\"\"\\\n",
    "            load csv from $attributesFile  as row\n",
    "            FIELDTERMINATOR \" \"\n",
    "            with toString(toInteger(row[0])) AS nodeId, row[1..] AS properties\n",
    "            MATCH (s:Node {id: nodeId})\n",
    "            WITH s, properties\n",
    "            UNWIND range(0, size(properties)-1) AS index\n",
    "            CALL apoc.create.setProperty(s, \"property_\" + index, toFloat(properties[index])) YIELD node\n",
    "            return count(*)\n",
    "            \"\"\", {\"attributesFile\": attributes_file})\n",
    "        print(result.summary().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to load our data into Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record loadMillis=52 computeMillis=63542 writeMillis=24 nodes=1005 writeProperty='embedding-python' embeddingSize=18 numberOfLayers=4 features=['max_out_neighbourhood( max_in_neighbourhood( IN_DEGREE))', 'max_out_neighbourhood( IN_DEGREE)', 'diffuse( hadamard_in_neighbourhood( max_out_neighbourhood( max_in_neighbourhood( IN_DEGREE))))', 'max_out_neighbourhood( mean_out_neighbourhood( IN_DEGREE))', 'diffuse( hadamard_out_neighbourhood( diffuse( rbf_out_neighbourhood( max_in_neighbourhood( IN_DEGREE)))))', 'hadamard_out_neighbourhood( IN_DEGREE)', 'max_out_neighbourhood( mean_out_neighbourhood( hadamard_out_neighbourhood( IN_DEGREE)))', 'IN_DEGREE', 'diffuse( rbf_out_neighbourhood( max_in_neighbourhood( IN_DEGREE)))', 'mean_out_neighbourhood( max_out_neighbourhood( IN_DEGREE))', 'max_in_neighbourhood( IN_DEGREE)', 'mean_out_neighbourhood( max_in_neighbourhood( IN_DEGREE))', 'mean_in_neighbourhood( max_out_neighbourhood( IN_DEGREE))', 'mean_out_neighbourhood( sum_out_neighbourhood( diffuse( rbf_out_neighbourhood( IN_DEGREE))))', 'mean_out_neighbourhood( max_out_neighbourhood( max_in_neighbourhood( IN_DEGREE)))', 'max_in_neighbourhood( mean_out_neighbourhood( hadamard_out_neighbourhood( IN_DEGREE)))', 'mean_out_neighbourhood( hadamard_out_neighbourhood( IN_DEGREE))', 'max_out_neighbourhood( diffuse( hadamard_both_neighbourhood( hadamard_out_neighbourhood( IN_DEGREE))))']>\n"
     ]
    }
   ],
   "source": [
    "embedding_property_name = \"embedding-python\"\n",
    "node_features = []\n",
    "pruning_lambda = 0.6\n",
    "diffusions = 3\n",
    "iterations = 3\n",
    "\n",
    "with driver.session() as session:\n",
    "    params = {\n",
    "        \"writeProperty\": embedding_property_name,\n",
    "        # this tells the procedure the name of the node attribute properties in the neo database\n",
    "        # the import function above calls them \"property_0\", \"property_1\", \"property_2\", ...\n",
    "        # this node_features argument should take a list of these names\n",
    "        # for the case of enzymes it should be from \"property_0\" to \"property_17\"\n",
    "        \"nodeFeatures\": node_features,\n",
    "        \"pruningLambda\": pruning_lambda,\n",
    "        \"diffusions\": diffusions,\n",
    "        \"iterations\": iterations\n",
    "    }\n",
    "    result = session.run(\"\"\"\n",
    "    call\n",
    "    algo.deepgl(\n",
    "        null,\n",
    "        null,\n",
    "        {nodeFeatures: $nodeFeatures,\n",
    "         pruningLambda: $pruningLambda,\n",
    "         diffusions: $diffusions,\n",
    "         iterations: $iterations,\n",
    "         writeProperty: $writeProperty})\n",
    "    \"\"\", params)\n",
    "    print(result.peek())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\\\n",
    "    MATCH (n) \n",
    "    WITH n.label as class, count(*) AS c\n",
    "    ORDER BY c DESC\n",
    "    WITH class WHERE c > 50\n",
    "    WITH class ORDER BY class\n",
    "    with collect(class) AS biggestClasses\n",
    "    MATCH (p:Node) WHERE p.label IN biggestClasses\n",
    "    RETURN p.`%s` AS embedding, apoc.coll.indexOf(biggestClasses, p.label) AS label, p.label as initialLabel\n",
    "    ORDER BY label\n",
    "    \"\"\" % embedding_property_name)\n",
    "\n",
    "    df = pd.DataFrame(dict(row) for row in result)\n",
    "\n",
    "emb = df[\"embedding\"].apply(pd.Series).values\n",
    "labels = df[\"label\"].values\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/anaconda3/envs/tsne_python/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Heatmap\n",
    "colours = ['r', 'g', 'b', 'black', 'y', 'orange']\n",
    "cols = pd.DataFrame(labels).apply(lambda x: colours[int(x)], axis=1).values\n",
    "\n",
    "dist = np.ndarray([len(emb), len(emb)])\n",
    "\n",
    "for i, e1 in enumerate(emb):\n",
    "    for j, e2 in enumerate(emb):\n",
    "        dist.itemset((i, j), np.linalg.norm(e1 - e2, 2))\n",
    "\n",
    "plt.imshow(dist)\n",
    "plt.axes().xaxis.tick_top()\n",
    "plt.xticks(np.arange(len(dist)), labels)\n",
    "plt.yticks(np.arange(len(dist)), labels)\n",
    "plt.show()\n",
    "\n",
    "# 2D Visualisation\n",
    "# from: https://baoilleach.blogspot.com/2014/01/convert-distance-matrix-to-2d.html\n",
    "adist = dist\n",
    "amax = np.amax(adist)\n",
    "adist /= amax\n",
    "\n",
    "mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\", random_state=6)\n",
    "results = mds.fit(adist)\n",
    "\n",
    "coords = results.embedding_\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(\n",
    "    coords[:, 0], coords[:, 1], marker='o', c=cols\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 1e-05, 'batch_size': 433, 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 30), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 10000, 'momentum': 0.9, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pete/anaconda3/envs/tsne_python/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:358: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7816091954022989\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(emb)\n",
    "y = labels\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "clf = MLPClassifier(solver='sgd',\n",
    "                    activation='tanh',\n",
    "                    learning_rate_init=0.001,\n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(30, 30),\n",
    "                    max_iter=10000,\n",
    "                    batch_size=X.shape[0],\n",
    "                    random_state=0)\n",
    "\n",
    "clf.n_outputs_ = 6\n",
    "clf.out_activation_ = \"softmax\"\n",
    "print(clf.get_params())\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "mean_acc = clf.score(test_x, test_y)\n",
    "print(mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
